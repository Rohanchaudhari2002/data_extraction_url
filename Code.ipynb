{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7418ef47-f26b-4446-8a2d-7c2f838a5966",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Received valid response.\n",
      "Success! Received valid response.\n",
      "Success! Received valid response.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import openpyxl\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Function to read stop words from a file\n",
    "def read_file_words(file_path, encodings=['utf-8', 'latin-1', 'ISO-8859-1', 'windows-1252']):\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding=encoding) as file:\n",
    "                stop_words = [line.strip() for line in file]\n",
    "            return stop_words\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    raise UnicodeDecodeError(\"Unable to decode the file using any of the specified encodings.\")\n",
    "\n",
    "\n",
    "# Function to calculate positive score\n",
    "def calculate_positive_score(text):\n",
    "    positive_score = sum(1 for word in text.split() if word.lower() in positive_words)\n",
    "    return positive_score\n",
    "\n",
    "# Function to calculate negative score\n",
    "def calculate_negative_score(text):\n",
    "    negative_score = sum(1 for word in text.split() if word.lower() in negative_words)\n",
    "    return negative_score\n",
    "def calculate_total_score(positive_score, negative_score):\n",
    "    if(positive_score+negative_score == 0):\n",
    "        return int(1)\n",
    "    return positive_score + negative_score\n",
    "# Function to calculate polarity score\n",
    "def calculate_polarity_score(positive_score, negative_score):\n",
    "    return positive_score - negative_score\n",
    "\n",
    "# Function to calculate subjective score\n",
    "def calculate_subjective_score(positive_score, negative_score):\n",
    "    return positive_score + negative_score\n",
    "\n",
    "# Function to split text into sentences\n",
    "def split_into_sentences(text):\n",
    "    # Define regular expression pattern for sentence boundary\n",
    "    pattern = r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s'\n",
    "    # Split text into sentences using regular expression\n",
    "    sentences = re.split(pattern, text)\n",
    "    return sentences\n",
    "# Function to calculate average sentence length\n",
    "def calculate_average_sentence_length(text):\n",
    "    # Split text into sentences\n",
    "    sentences = split_into_sentences(text)\n",
    "    # Calculate total number of words and total number of sentences\n",
    "    total_words = sum(len(sentence.split()) for sentence in sentences)\n",
    "    total_sentences = len(sentences)\n",
    "    # Calculate average sentence length\n",
    "    if total_sentences > 0:\n",
    "        average_length = total_words / total_sentences\n",
    "    else:\n",
    "        average_length = 0\n",
    "    return average_length\n",
    "\n",
    "# Function to count syllables in a word\n",
    "def count_syllables(word):\n",
    "    # Simple syllable counting algorithm (not perfect)\n",
    "    # Count consecutive vowels as syllables, but exclude certain combinations\n",
    "    vowels = 'aeiouy'\n",
    "    count = 0\n",
    "    word = word.lower()\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)):\n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            count += 1\n",
    "    if word.endswith('e'):\n",
    "        count -= 1\n",
    "    if count == 0:\n",
    "        count = 1  # At least one syllable for words like 'a', 'I'\n",
    "    return count\n",
    "\n",
    "# Function to calculate percentage of complex words in text\n",
    "def calculate_complexity_percentage(text, threshold_syllables=3):\n",
    "    # Tokenize text into words\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    # Count total words and complex words\n",
    "    total_words = len(words)\n",
    "    complex_words = sum(1 for word in words if count_syllables(word) >= threshold_syllables)\n",
    "    # Calculate percentage\n",
    "    if total_words > 0:\n",
    "        percentage = (complex_words / total_words) * 100\n",
    "    else:\n",
    "        percentage = 0\n",
    "    return percentage\n",
    "\n",
    "# Function to count syllables in a word\n",
    "def count_syllables(word):\n",
    "    # Simple syllable counting algorithm (not perfect)\n",
    "    # Count consecutive vowels as syllables, but exclude certain combinations\n",
    "    vowels = 'aeiouy'\n",
    "    count = 0\n",
    "    word = word.lower()\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)):\n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            count += 1\n",
    "    if word.endswith('e'):\n",
    "        count -= 1\n",
    "    if count == 0:\n",
    "        count = 1  # At least one syllable for words like 'a', 'I'\n",
    "    return count\n",
    "\n",
    "# Function to calculate percentage of complex words in text\n",
    "def calculate_complexity_percentage(text, threshold_syllables=3):\n",
    "    # Tokenize text into words\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    # Count total words and complex words\n",
    "    total_words = len(words)\n",
    "    complex_words = sum(1 for word in words if count_syllables(word) >= threshold_syllables)\n",
    "    # Calculate percentage\n",
    "    if total_words > 0:\n",
    "        percentage = (complex_words / total_words) * 100\n",
    "    else:\n",
    "        percentage = 0\n",
    "    return percentage\n",
    "# Function to calculate Gunning Fog Index\n",
    "def calculate_gunning_fog_index(text):\n",
    "    # Tokenize text into sentences\n",
    "    sentences = re.split(r'[.!?]', text)\n",
    "    # Count total words and complex words\n",
    "    total_words = 0\n",
    "    complex_words = 0\n",
    "    for sentence in sentences:\n",
    "        # Tokenize sentence into words\n",
    "        words = re.findall(r'\\b\\w+\\b', sentence.lower())\n",
    "        # Count total words\n",
    "        total_words += len(words)\n",
    "        if(total_words == 0):\n",
    "            total_words = 1\n",
    "        # Count complex words\n",
    "        for word in words:\n",
    "            if count_syllables(word) >= 3:\n",
    "                complex_words += 1\n",
    "    # Calculate average sentence length (ASL)\n",
    "    average_sentence_length = total_words / len(sentences)\n",
    "    # Calculate percentage of complex words\n",
    "    percentage_complex_words = (complex_words / total_words) * 100\n",
    "    # Calculate Gunning Fog Index\n",
    "    fog_index = 0.4 * (average_sentence_length + percentage_complex_words)\n",
    "    return fog_index\n",
    "\n",
    "\n",
    "\n",
    "# Function to calculate average word per sentence\n",
    "def calculate_avg_words_per_sentence(text):\n",
    "    # Tokenize text into sentences\n",
    "    sentences = re.split(r'[.!?]', text)\n",
    "    # Count total words and total sentences\n",
    "    total_words = 0\n",
    "    total_sentences = len(sentences)\n",
    "    # Iterate through each sentence\n",
    "    for sentence in sentences:\n",
    "        # Tokenize sentence into words\n",
    "        words = re.findall(r'\\b\\w+\\b', sentence)\n",
    "        # Update total words count\n",
    "        total_words += len(words)\n",
    "    # Calculate average words per sentence\n",
    "    if total_sentences > 0:\n",
    "        avg_words_per_sentence = total_words / total_sentences\n",
    "    else:\n",
    "        avg_words_per_sentence = 0\n",
    "    return avg_words_per_sentence\n",
    "# Function to count syllables in a word\n",
    "def count_syllables(word):\n",
    "    # Simple syllable counting algorithm (not perfect)\n",
    "    # Count consecutive vowels as syllables, but exclude certain combinations\n",
    "    vowels = 'aeiouy'\n",
    "    count = 0\n",
    "    word = word.lower()\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)):\n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            count += 1\n",
    "    if word.endswith('e'):\n",
    "        count -= 1\n",
    "    if count == 0:\n",
    "        count = 1  # At least one syllable for words like 'a', 'I'\n",
    "    return count\n",
    "\n",
    "# Function to calculate counts and averages\n",
    "def calculate_counts_and_averages(text):\n",
    "    # Tokenize text into words\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    # Initialize counts\n",
    "    complex_word_count = 0\n",
    "    total_word_count = len(words)\n",
    "    total_syllable_count = 0\n",
    "    # Calculate counts and total syllable count\n",
    "    for word in words:\n",
    "        syllable_count = count_syllables(word)\n",
    "        total_syllable_count += syllable_count\n",
    "        if syllable_count >= 3:\n",
    "            complex_word_count += 1\n",
    "    # Calculate average syllables per word\n",
    "    if total_word_count > 0:\n",
    "        avg_syllables_per_word = total_syllable_count / total_word_count\n",
    "    else:\n",
    "        avg_syllables_per_word = 0\n",
    "    return complex_word_count, total_word_count, avg_syllables_per_word\n",
    "\n",
    "# Function to calculate counts and averages\n",
    "def calculate_counts_and_averages(text):\n",
    "    # Tokenize text into words\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    # Initialize counts\n",
    "    personal_pronoun_count = 0\n",
    "    total_word_count = len(words)\n",
    "    total_character_count = sum(len(word) for word in words)\n",
    "    # List of personal pronouns\n",
    "    personal_pronouns = [\"i\", \"you\", \"he\", \"she\", \"it\", \"we\", \"they\", \"me\", \"him\", \"her\", \"us\", \"them\", \"my\", \"your\", \"his\", \"her\", \"its\", \"our\", \"their\", \"mine\", \"yours\", \"hers\", \"ours\", \"theirs\"]\n",
    "    # Count occurrences of personal pronouns\n",
    "    for word in words:\n",
    "        if word in personal_pronouns:\n",
    "            personal_pronoun_count += 1\n",
    "    # Calculate average word length\n",
    "    if total_word_count > 0:\n",
    "        avg_word_length = total_character_count / total_word_count\n",
    "    else:\n",
    "        avg_word_length = 0\n",
    "    return personal_pronoun_count, total_word_count, avg_word_length\n",
    "\n",
    "def remove_duplicates(csv_file, column_index):\n",
    "    # Read the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Remove duplicate rows based on the specified column\n",
    "    df.drop_duplicates(subset=df.columns[column_index], inplace=True)\n",
    "    \n",
    "    # Write the DataFrame back to the same CSV file, overwriting the existing content\n",
    "    df.to_csv(csv_file, index=False)\n",
    "\n",
    "\n",
    "# Load the workbook\n",
    "workbook = openpyxl.load_workbook('Input.xlsx')\n",
    "# active the workbook\n",
    "worksheet = workbook.active\n",
    "# access the input data from xlsx\n",
    "url_value = worksheet['B1'].value\n",
    "\n",
    "# Select the 'url' column\n",
    "url_index = 2\n",
    "# create a list to store the url in one list\n",
    "url_values = []\n",
    "\n",
    "# Read stop words from each txt file and combine them\n",
    "all_stop_words = []\n",
    "stop_word_files = read_file_words(\"stop_words_english.txt\")\n",
    "\n",
    "# If your stop word or any txt file is inside any folder use following for loop code\n",
    "# for file_name in stop_word_files:\n",
    "#     file_path = os.path.join(\"/file_path\", file_name)\n",
    "#     all_stop_words.extend(read_file_words(file_path))\n",
    "\n",
    "# Read positive and Negative words from txt file\n",
    "positive_words = read_file_words(\"positive-words.txt\")\n",
    "negative_words = read_file_words(\"negative-words.txt\")\n",
    "\n",
    "\n",
    "\n",
    "max_row = worksheet.max_row\n",
    "# create a loop to store all the url column value in the list\n",
    "for row in worksheet.iter_rows(min_row=2, max_row=max_row, min_col=url_index, max_col=url_index):\n",
    "    for cell in row:\n",
    "        url_values.append(cell.value)\n",
    "\n",
    "# create a list to store the words\n",
    "words_sorted = []\n",
    "\n",
    "# Scrape data from each URL\n",
    "for url_link in url_values:\n",
    "    url = url_link\n",
    "    response = requests.get(url, allow_redirects=False)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Success! Received valid response.\")\n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find all paragraph from class tags and extract text\n",
    "        paragraphs = soup.find_all(class_ = 'mw-body-content')\n",
    "        \n",
    "        # for element in paragraphs:\n",
    "        #     paragraphs = element.find_all('p','ol')\n",
    "        #     for paragraph in paragraphs:\n",
    "        #         # Skip specific paragraph(s) from class\n",
    "        #         if 'paragraph_to_skip' in paragraph.get('wp-block-preformatted', []):\n",
    "        #             continue\n",
    "        #         words_sorted.append(paragraph.get_text())\n",
    "\n",
    "        for element in paragraphs:\n",
    "            # Check if the element is a div\n",
    "            if element.name == 'div':\n",
    "                # Find all paragraphs and ignore <pre> tags within the div\n",
    "                paragraphs_within_div = element.find_all(['p', 'ol', 'li'])\n",
    "                for sub_element in paragraphs_within_div:\n",
    "                    # Check if the sub-element is a <pre> tag\n",
    "                    if sub_element.name == 'pre':\n",
    "                        continue  # Skip <pre> tags\n",
    "                    else:\n",
    "                        # Append text from non-<pre> sub-elements to words_sorted\n",
    "                        words_sorted.append(sub_element.get_text())\n",
    "            else:\n",
    "                # Append text from non-div elements directly to words_sorted\n",
    "                words_sorted.append(element.get_text())\n",
    "\n",
    "\n",
    "                    # words_sorted.append(element.get_text())\n",
    "        # Extract text from each paragraph and filter out stop words\n",
    "        for paragraph in words_sorted:  \n",
    "            words = paragraph.split()\n",
    "            # Filter out stop words\n",
    "            filtered_words = [word for word in words if word.lower() not in all_stop_words]\n",
    "            filtered_text = ' '.join(filtered_words)\n",
    "            # print(filtered_text)\n",
    "        positive_score = calculate_positive_score(filtered_text)\n",
    "        negative_score = calculate_negative_score(filtered_text)\n",
    "        total_score = calculate_total_score(positive_score,negative_score)\n",
    "        polarity_score = calculate_polarity_score(positive_score, negative_score)/total_score\n",
    "        subjective_score = calculate_subjective_score(positive_score, negative_score)/total_score\n",
    "        average_length = calculate_average_sentence_length(filtered_text)\n",
    "        complexity_percentage = calculate_complexity_percentage(filtered_text)\n",
    "        personal_pronoun_count, total_word_count, avg_word_length = calculate_counts_and_averages(filtered_text)\n",
    "        complex_word_count, total_word_count, avg_syllables_per_word = calculate_counts_and_averages(filtered_text)\n",
    "        \n",
    "        gunning_fog_index = calculate_gunning_fog_index(filtered_text)\n",
    "       \n",
    "        avg_words_per_sentence = calculate_avg_words_per_sentence(filtered_text)\n",
    "        \n",
    "#         You can also print all the output here\n",
    "#         print(\"Positive score:\", positive_score)\n",
    "#         print(\"Negative score:\", negative_score)\n",
    "#         print(\"Polarity score:\", polarity_score)\n",
    "#         print(\"Subjective score:\", subjective_score)\n",
    "#         print(\"Average sentence length:\", average_length)\n",
    "#         print(\"Percentage of complex words:\", complexity_percentage)\n",
    "#         print(\"Gunning Fog Index:\", gunning_fog_index)\n",
    "#         print(\"Average words per sentence:\", avg_words_per_sentence)\n",
    "#         print(\"Complex word count:\", complex_word_count)\n",
    "        \n",
    "        \n",
    "#         print(\"Total word count:\", total_word_count)\n",
    "#         print(\"Average syllables per word:\", avg_syllables_per_word)\n",
    "\n",
    "#         print(\"Personal pronoun count:\", personal_pronoun_count)\n",
    "#         print(\"Total word count:\", total_word_count)\n",
    "#         print(\"Average word length:\", avg_word_length)\n",
    "        \n",
    "        # Write extracted information to a CSV file\n",
    "        with open('output.csv', mode='a', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            if os.stat('output.csv').st_size == 0:  # Check if file is empty\n",
    "                writer.writerow(['url', 'POSITIVE SCORE', 'NEGATIVE SCORE', 'POLARITY SCORE', 'SUBJECTIVITY SCORE', 'AVG SENTENCE LENGTH',\n",
    "                                 'PERCENTAGE OF COMPLEX WORDS', 'FOG INDEX', 'AVG NUMBER OF WORDS PER SENTENCE', 'COMPLEX WORD COUNT', 'WORD COUNT', 'SYLLABLE PER WORD', 'PERSONAL PRONOUNS',\n",
    "                                 'AVG WORD LENGTH'])\n",
    "            writer.writerow([url, positive_score, negative_score, polarity_score, subjective_score, average_length,\n",
    "                             complexity_percentage, gunning_fog_index, avg_words_per_sentence, complex_word_count, total_word_count, avg_syllables_per_word, personal_pronoun_count,\n",
    "                             avg_word_length])\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        print(\"Error! Failed to receive valid response. Status code:\", response.status_code)\n",
    "csv_file = 'output.csv'  \n",
    "column_index = 0  \n",
    "remove_duplicates(csv_file, column_index)\n",
    "# Don't forget to close the workbook when you're done\n",
    "workbook.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfc22cf-cfe0-464f-af76-a8dd97890301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
